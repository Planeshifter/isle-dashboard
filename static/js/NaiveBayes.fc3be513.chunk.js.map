{"version":3,"sources":["../node_modules/@stdlib/stdlib/lib/node_modules/@stdlib/assert/is-array-array/lib/index.js","../node_modules/@babel/runtime/helpers/esm/readOnlyError.js","../node_modules/@stdlib/stdlib/lib/node_modules/@stdlib/assert/is-array-array/lib/main.js","../node_modules/@isle-project/components/models/naive-bayes/design_matrix.js","../node_modules/@isle-project/components/models/naive-bayes/score.js","../node_modules/@isle-project/components/models/naive-bayes/gaussian.js","../node_modules/@isle-project/components/models/naive-bayes/multinomial.js","../node_modules/@isle-project/components/models/naive-bayes/main.js","../node_modules/@isle-project/components/models/naive-bayes/naive_bayes.js","../node_modules/@isle-project/utils/subtract/index.js"],"names":["isArrayArray","module","exports","_readOnlyError","name","TypeError","arrayfun","isMissing","x","isnan","isUndefinedOrNull","isNonMissingNumber","isNumber","designMatrix","y","data","quantitative","matrix","predictors","hash","isArray","j","length","values","contains","push","categories","extractCategoriesFromValues","k","nobs","i","row","val","ndarray","yvalues","designMatrixMissing","missing","score","isArrayLike","yhat","this","predict","n","accuracy","GaussianFit","shape","p","classes","uniq","slice","nclass","fitGaussian","prototype","require","prior","mu","Float64Array","sigma","ids","c","nc","ln","vals","map","get","mean","stdev","set","calcGaussianProb","res","s2","PI","pow","predictOne","nClasses","logLik","Array","max","argmax","isMatrixLike","nrow","ncol","ret","arr","predictProbs","a","summand","exp","denom","subtract","sum","out","MultinomialFit","alpha","fitMultinomial","cprob","counts","Int32Array","totalCount","calcMultinomProb","addResources","COUNTER","fitModel","omitMissing","result","gaussian","error","NaiveBayes","props","onPredict","state","t","style","overflowX","width","className","counter","bordered","size","key","toFixed","pred","_","summaryTable","tooltip","Button","variant","onClick","handlePrediction","Alert","nextProps","prevState","Component","defaultProps","withTranslation","isArr","len","Error"],"mappings":";4FAqCA,IAAIA,EAAe,EAAQ,MAG3BC,EAAOC,QAAUF,G,kCCxCF,SAASG,EAAeC,GACrC,MAAM,IAAIC,UAAU,IAAOD,EAAO,kBADpC,mC,kCCmBA,IAwBIJ,EAxBW,EAAQ,IAwBJM,CAtBL,EAAQ,KAwBtBL,EAAOC,QAAUF,G,kCC7CjB,gLAaA,SAASO,EAAWC,GACnB,OAAOC,IAAOD,IAAOE,IAAmBF,GAGzC,SAASG,EAAoBH,GAC5B,OAAOI,sBAAUJ,KAAQC,IAAOD,GAM1B,SAASK,EAAcL,EAAGM,EAAGC,EAAMC,GACzC,IAAIC,EAAS,GACPC,EAAa,GACbC,EAAO,GACPC,IAASZ,KACdA,EAAI,CAAEA,IAEP,IAAM,IAAIa,EAAI,EAAGA,EAAIb,EAAEc,OAAQD,IAAM,CACpC,IAAME,EAASR,EAAMP,EAAGa,IACxB,GAAKG,IAAUR,EAAcR,EAAGa,IAC/BH,EAAWO,KAAMjB,EAAGa,QACd,CAEN,IADA,IAAMK,EAAaC,YAA6BJ,EAAQf,EAAGa,IACjDO,EAAI,EAAGA,EAAIF,EAAWJ,OAAQM,IACvCV,EAAWO,KAAX,UAAoBjB,EAAGa,GAAvB,YAA8BK,EAAYE,KAE3CT,EAAMX,EAAGa,IAAQK,GAInB,IADA,IAAMG,EAAOd,EAAMP,EAAG,IAAMc,OAClBQ,EAAI,EAAGA,EAAID,EAAMC,IAAM,CAEhC,IADA,IAAMC,EAAM,GACFV,EAAI,EAAGA,EAAIb,EAAEc,OAAQD,IAAM,CACpC,IAAME,EAASR,EAAMP,EAAGa,IACxB,GAAKG,IAAUR,EAAcR,EAAGa,IAC/BU,EAAIN,KAAMF,EAAQO,SAIlB,IAFA,IAAMJ,EAAaP,EAAMX,EAAGa,IACtBW,EAAMT,EAAQO,GACVF,EAAI,EAAGA,EAAIF,EAAWJ,OAAQM,IACvCG,EAAIN,KAAQO,IAAQN,EAAYE,GAAQ,EAAI,GAI/CX,EAAOQ,KAAMM,GAId,MAAO,CAAEd,OAFTA,EAASgB,IAAShB,GAEDC,aAAYgB,QADbnB,EAAMD,IAIhB,SAASqB,EAAqB3B,EAAGM,EAAGC,EAAMC,GAChD,IAAIC,EAAS,GACPC,EAAa,GACbC,EAAO,GACPC,IAASZ,KACdA,EAAI,CAAEA,IAEP,IAAM,IAAIa,EAAI,EAAGA,EAAIb,EAAEc,OAAQD,IAAM,CACpC,IAAME,EAASR,EAAMP,EAAGa,IACxB,GAAKG,IAAUR,EAAcR,EAAGa,IAC/BH,EAAWO,KAAMjB,EAAGa,QACd,CAEN,IADA,IAAMK,EAAaC,YAA6BJ,EAAQf,EAAGa,IACjDO,EAAI,EAAGA,EAAIF,EAAWJ,OAAQM,IACvCV,EAAWO,KAAX,UAAoBjB,EAAGa,GAAvB,YAA8BK,EAAYE,KAE3CT,EAAMX,EAAGa,IAAQK,GAKnB,IAFA,IAAMG,EAAOd,EAAMP,EAAG,IAAMc,OACtBY,EAAU,GACNJ,EAAI,EAAGA,EAAID,EAAMC,IAAM,CAGhC,IAFA,IAAMC,EAAM,GACRK,GAAU,EACJf,EAAI,EAAGA,EAAIb,EAAEc,OAAQD,IAAM,CACpC,IAAME,EAASR,EAAMP,EAAGa,IACxB,GAAKG,IAAUR,EAAcR,EAAGa,IAC1BV,EAAoBY,EAAQO,IAChCC,EAAIN,KAAMF,EAAQO,IAElBM,GAAU,MAEL,CACN,IAAMV,EAAaP,EAAMX,EAAGa,IACtBW,EAAMT,EAAQO,GACpB,GAAKvB,EAAWyB,GACfI,GAAU,OAEV,IAAM,IAAIR,EAAI,EAAGA,EAAIF,EAAWJ,OAAQM,IACvCG,EAAIN,KAAQO,IAAQN,EAAYE,GAAQ,EAAI,IAK3CrB,EAAWQ,EAAMD,GAAKgB,MAC1BM,GAAU,GAELA,IACLnB,EAAOQ,KAAMM,GACbG,EAAQT,KAAMV,EAAMD,GAAKgB,KAI3B,MAAO,CAAEb,OADTA,EAASgB,IAAShB,GACDC,aAAYgB,a,kCCtH9B,6BAoCeG,UAtBf,SAAgB7B,EAAGM,GAClB,IAAMwB,IAAa9B,GAClB,MAAM,IAAIH,UAAW,oFAAsFG,EAAI,KAEhH,IAAM8B,IAAaxB,GAClB,MAAM,IAAIT,UAAW,2FAA6FS,EAAI,KAKvH,IAHA,IAAMyB,EAAOC,KAAKC,QAASjC,GACrBkC,EAAI5B,EAAEQ,OACRqB,EAAW,EACLb,EAAI,EAAGA,EAAIY,EAAGZ,IAClBS,EAAMT,KAAQhB,EAAGgB,KACrBa,GAAY,GAId,OADAA,GAAYD,I,0aCHb,SAASE,EAAapC,EAAGM,GACxB0B,KAAKE,EAAIlC,EAAEqC,MAAO,GAClBL,KAAKM,EAAItC,EAAEqC,MAAO,GAElBL,KAAKO,QAAUC,IAAMlC,EAAEmC,SACvBT,KAAKU,OAASV,KAAKO,QAAQzB,OAE3BkB,KAAKW,YAAa3C,EAAGM,GAGtB8B,EAAYQ,UAAUf,MAAQgB,EAAS,MAcvCT,EAAYQ,UAAUD,YAAc,SAAsB3C,EAAGM,GAAK,IAAD,OAChE0B,KAAKc,MAAQ,GACb,IAAMT,EAAQ,CAAEL,KAAKM,EAAGN,KAAKU,QAC7BV,KAAKe,GAAKtB,IAAS,IAAIuB,aAAcX,EAAM,GAAGA,EAAM,IAAM,CAAE,MAASA,IACrEL,KAAKiB,MAAQxB,IAAS,IAAIuB,aAAcX,EAAM,GAAGA,EAAM,IAAM,CAAE,MAASA,IACxE,IAAM,IAAIf,EAAI,EAAGA,EAAIU,KAAKU,OAAQpB,IAAM,CAGvC,IAFA,IAAM4B,EAAM,GACNC,EAAInB,KAAKO,QAASjB,GACdT,EAAI,EAAGA,EAAImB,KAAKE,EAAGrB,IACvBP,EAAGO,KAAQsC,GACfD,EAAIjC,KAAMJ,GAGZ,IAAMuC,EAAKF,EAAIpC,OACfkB,KAAKc,MAAOK,GAAME,IAAID,EAAKpB,KAAKE,GAChC,IAVuC,eAU7BrB,GACT,IAAMyC,EAAOJ,EAAIK,KAAK,SAAAjC,GAAC,OAAItB,EAAEwD,IAAKlC,EAAGT,MAC/BkC,EAAKU,YAAMH,GACXL,EAAQS,YAAOJ,GACrB,EAAKP,GAAGY,IAAK9C,EAAGS,EAAGyB,GACnB,EAAKE,MAAMU,IAAK9C,EAAGS,EAAG2B,IALbpC,EAAI,EAAGA,EAAImB,KAAKM,EAAGzB,IAAO,EAA1BA,KAiBZuB,EAAYQ,UAAUgB,iBAAmB,SAA2B5D,EAAGsB,GAItE,IAHA,IAAM6B,EAAInB,KAAKO,QAASjB,GACpBuC,EAAM7B,KAAKc,MAAOK,GAEZtC,EAAI,EAAGA,EAAImB,KAAKM,EAAGzB,IAAM,CAClC,IAAMoC,EAAQjB,KAAKiB,MAAMO,IAAK3C,EAAGS,GAC3BwC,EAAKb,EAAMA,EACXF,EAAKf,KAAKe,GAAGS,IAAK3C,EAAGS,GAE3BuC,IADe,GAAMR,IAAI,EAAIU,IAAKD,GAAWE,IAAKhE,EAAGa,GAAMkC,EAAI,GAAMe,EAGtE,OAAOD,GASRzB,EAAYQ,UAAUqB,WAAa,SAAqBjE,GAGvD,IAFA,IAAMkE,EAAWlC,KAAKO,QAAQzB,OACxBqD,EAAS,IAAIC,MAAOF,GAChB5C,EAAI,EAAGA,EAAI4C,EAAU5C,IAC9B6C,EAAQ7C,GAAMU,KAAK4B,iBAAkB5D,EAAGsB,GAIzC,IAFA,IAAI+C,EAAMF,EAAQ,GACdG,EAAStC,KAAKO,QAAS,GACjBjB,EAAI,EAAGA,EAAI4C,EAAU5C,IAAM,CACpC,IAAME,EAAM2C,EAAQ7C,GACfE,EAAM6C,IACVA,EAAM7C,EACN8C,EAAStC,KAAKO,QAASjB,IAGzB,OAAOgD,GASRlC,EAAYQ,UAAUX,QAAU,SAAkBjC,GACjD,IAAMkE,EAAWlC,KAAKO,QAAQzB,OAK9B,GAJKtB,IAAcQ,KAClBA,EAAIyB,IAASzB,IAGTuE,IAAcvE,GAAM,CAGxB,IAHyB,IAAD,cACDA,EAAEqC,MADD,GAChBmC,EADgB,KACVC,EADU,KAElBC,EAAM,IAAIN,MAAOI,GACblD,EAAI,EAAGA,EAAIkD,EAAMlD,IAAM,CAEhC,IADA,IAAM6C,EAAS,IAAIC,MAAOF,GAChBrD,EAAI,EAAGA,EAAIqD,EAAUrD,IAAM,CAEpC,IADA,IAAM8D,EAAM,IAAIP,MAAOK,GACbrD,EAAI,EAAGA,EAAIqD,EAAMrD,IAC1BuD,EAAKvD,GAAMpB,EAAEwD,IAAKlC,EAAGF,GAEtB+C,EAAQtD,GAAMmB,KAAK4B,iBAAkBe,EAAK9D,GAI3C,IAFA,IAAIwD,EAAMF,EAAQ,GACdG,EAAStC,KAAKO,QAAS,GACjB1B,EAAI,EAAGA,EAAIqD,EAAUrD,IAAM,CACpC,IAAMW,EAAM2C,EAAQtD,GACfW,EAAM6C,IACVA,EAAM7C,EACN8C,EAAStC,KAAKO,QAAS1B,IAGzB6D,EAAKpD,GAAMgD,EAEZ,OAAOI,EAGR,OAAO1C,KAAKiC,WAAYjE,IASzBoC,EAAYQ,UAAUgC,aAAe,SAAuB5E,GAK3D,GAJKR,IAAcQ,KAClBA,EAAIyB,IAASzB,IAGTuE,IAAcvE,GAAM,CAGxB,IAHyB,IAAD,cACDA,EAAEqC,MADD,GAChBmC,EADgB,KACVC,EADU,KAElBC,EAAM,IAAIN,MAAOI,GACblD,EAAI,EAAGA,EAAIkD,EAAMlD,IAAM,CAEhC,IADA,IAAI6C,EAAS,IAAIC,MAAOpC,KAAKU,QACnB7B,EAAI,EAAGA,EAAImB,KAAKU,OAAQ7B,IAAM,CAEvC,IADA,IAAM8D,EAAM,IAAIP,MAAOK,GACbrD,EAAI,EAAGA,EAAIqD,EAAMrD,IAC1BuD,EAAKvD,GAAMpB,EAAEwD,IAAKlC,EAAGF,GAEtB+C,EAAQtD,GAAMmB,KAAK4B,iBAAkBe,EAAK9D,GAI3C,IAFA,IAAMgE,EAAIR,YAAKF,GACXW,EAAU,EACJjE,EAAI,EAAGA,EAAIsD,EAAOrD,OAAQD,IACnCiE,GAAWC,IAAKZ,EAAQtD,GAAMgE,GAE/B,IAAMG,EAAQH,EAAIxB,IAAIyB,GACtBX,EAASc,YAAUd,EAAQa,GAC3BN,EAAKpD,GAAM6C,EAAOZ,KAAK,SAAAvD,GAAC,OAAI+E,IAAK/E,MAElC,OAAO0E,EAIR,IADA,IAAMP,EAAS,IAAIC,MAAOpC,KAAKU,QACrB7B,EAAI,EAAGA,EAAImB,KAAKU,OAAQ7B,IACjCsD,EAAQtD,GAAMmB,KAAK4B,iBAAkB5D,EAAGa,GAIzC,IAFA,IAAMgE,EAAIR,YAAKF,GACXW,EAAU,EACJjE,EAAI,EAAGA,EAAIsD,EAAOrD,OAAQD,IACnCiE,GAAWC,IAAKZ,EAAQtD,GAAMgE,GAE/B,IAAMG,EAAQH,EAAIxB,IAAIyB,GAEtB,OADM,uBAANX,EAASc,YAAUd,EAAQa,IACbzB,KAAK,SAAAvD,GAAC,OAAI+E,IAAK/E,OAMfoC,QCvMT8C,EAAM,SAAEP,GAEb,IADA,IAAIQ,EAAM,EACA7D,EAAI,EAAGA,EAAIqD,EAAI7D,OAAQQ,IAChC6D,GAAOR,EAAKrD,GAEb,OAAO6D,GAeR,SAASC,EAAgBpF,EAAGM,EAAG+E,GAC9BrD,KAAKE,EAAIlC,EAAEqC,MAAO,GAClBL,KAAKM,EAAItC,EAAEqC,MAAO,GAElBL,KAAKO,QAAUC,IAAMlC,EAAEmC,SACvBT,KAAKU,OAASV,KAAKO,QAAQzB,OAC3BkB,KAAKqD,MAAQA,EAEbrD,KAAKsD,eAAgBtF,EAAGM,GAGzB8E,EAAexC,UAAUf,MAAQgB,EAAS,MAc1CuC,EAAexC,UAAU0C,eAAiB,SAAyBtF,EAAGM,GAIrE,IAHA,IAAMwC,EAAQ,GACRT,EAAQ,CAAEL,KAAKM,EAAGN,KAAKU,QACvB6C,EAAQ9D,IAAS,IAAIuB,aAAcX,EAAM,GAAGA,EAAM,IAAM,CAAE,MAASA,IAC/Df,EAAI,EAAGA,EAAIU,KAAKU,OAAQpB,IAAM,CAIvC,IAHA,IAAM4B,EAAM,GACNsC,EAAS,IAAIC,WAAYzD,KAAKM,GAC9Ba,EAAInB,KAAKO,QAASjB,GACdT,EAAI,EAAGA,EAAImB,KAAKE,EAAGrB,IACvBP,EAAGO,KAAQsC,GACfD,EAAIjC,KAAMJ,GAGZ,IAAMuC,EAAKF,EAAIpC,OACfgC,EAAOK,GAAME,IAAID,EAAKpB,KAAKE,GAE3B,IADA,IAAIwD,EAAa,EAXsB,WAY7B7E,GACT,IAAMyC,EAAOJ,EAAIK,KAAK,SAAAjC,GAAC,OAAItB,EAAEwD,IAAKlC,EAAGT,MACrC2E,EAAQ3E,GAAMqE,EAAK5B,GACnBoC,GAAcF,EAAQ3E,IAHbA,EAAI,EAAGA,EAAImB,KAAKM,EAAGzB,IAAO,EAA1BA,GAKV,IAAM,IAAIA,EAAI,EAAGA,EAAImB,KAAKM,EAAGzB,IAAM,CAClC,IAAMW,EAAM6B,IAAImC,EAAQ3E,GAAMmB,KAAKqD,OAAUhC,IAAIqC,EAAa1D,KAAKM,EAAIN,KAAKqD,OAC5EE,EAAM5B,IAAK9C,EAAGS,EAAGE,IAGnBQ,KAAKc,MAAQA,EACbd,KAAKuD,MAAQA,GAWdH,EAAexC,UAAU+C,iBAAmB,SAA2B3F,EAAGsB,EAAGT,GAC5E,IAAMsC,EAAInB,KAAKO,QAASjB,GACpBuC,EAAM7B,KAAKc,MAAOK,GACtB,IAAMtC,EAAI,EAAGA,EAAImB,KAAKM,EAAGzB,IAAM,CAE9BgD,GADY7D,EAAGa,GAAMb,EAAGa,GAAMmB,KAAKuD,MAAM/B,IAAK3C,EAAGS,GAAM,EAGxD,OAAOuC,GASRuB,EAAexC,UAAUqB,WAAa,SAAqBjE,GAG1D,IAFA,IAAMkE,EAAWlC,KAAKO,QAAQzB,OACxBqD,EAAS,IAAIC,MAAOF,GAChB5C,EAAI,EAAGA,EAAI4C,EAAU5C,IAAM,CACpC,IAAM6B,EAAInB,KAAKO,QAASjB,GACxB6C,EAAQ7C,GAAMU,KAAKc,MAAOK,GAC1B,IAAM,IAAItC,EAAI,EAAGA,EAAImB,KAAKM,EAAGzB,IAAM,CAClC,IAAMW,EAAMxB,EAAGa,GAAMb,EAAGa,GAAMmB,KAAKuD,MAAM/B,IAAK3C,EAAGS,GAAM,EACvD6C,EAAQ7C,IAAOE,GAKjB,IAFA,IAAI6C,EAAMF,EAAQ,GACdG,EAAStC,KAAKO,QAAS,GACjBjB,EAAI,EAAGA,EAAI4C,EAAU5C,IAAM,CACpC,IAAME,EAAM2C,EAAQ7C,GACfE,EAAM6C,IACVA,EAAM7C,EACN8C,EAAStC,KAAKO,QAASjB,IAGzB,OAAOgD,GASRc,EAAexC,UAAUX,QAAU,SAAkBjC,GACpD,IAAMkE,EAAWlC,KAAKO,QAAQzB,OAK9B,GAJKtB,IAAcQ,KAClBA,EAAIyB,IAASzB,IAGTuE,IAAcvE,GAAM,CAGxB,IAFA,IAAM0E,EAAM,GACNF,EAAOxE,EAAEqC,MAAO,GACZf,EAAI,EAAGA,EAAIkD,EAAMlD,IAAM,CAEhC,IADA,IAAM6C,EAAS,IAAIC,MAAOF,GAChBrD,EAAI,EAAGA,EAAIqD,EAAUrD,IAAM,CACpC,IAAMsC,EAAInB,KAAKO,QAAS1B,GACxBsD,EAAQtD,GAAMmB,KAAKc,MAAOK,GAC1B,IAAM,IAAI/B,EAAI,EAAGA,EAAIY,KAAKM,EAAGlB,IAAM,CAClC,IAAMI,EAAMxB,EAAEwD,IAAKlC,EAAGF,GAAMpB,EAAEwD,IAAKlC,EAAGF,GAAMY,KAAKuD,MAAM/B,IAAKpC,EAAGP,GAAM,EACrEsD,EAAQtD,IAAOW,GAKjB,IAFA,IAAI6C,EAAMF,EAAQ,GACdG,EAAStC,KAAKO,QAAS,GACjB1B,EAAI,EAAGA,EAAIqD,EAAUrD,IAAM,CACnC,IAAMW,EAAM2C,EAAQtD,GACfW,EAAM6C,IACVA,EAAM7C,EACN8C,EAAStC,KAAKO,QAAS1B,IAG1B6D,EAAKpD,GAAMgD,EAEZ,OAAOI,EAGR,OAAO1C,KAAKiC,WAAYjE,IASzBoF,EAAexC,UAAUgC,aAAe,SAAuB5E,GAK9D,GAJKR,IAAcQ,KAClBA,EAAIyB,IAASzB,IAGTuE,IAAcvE,GAAM,CAGxB,IAFA,IAAMwE,EAAOxE,EAAEqC,MAAO,GAChBqC,EAAM,IAAIN,MAAOI,GACblD,EAAI,EAAGA,EAAIkD,EAAMlD,IAAM,CAEhC,IADA,IAAI6C,EAAS,IAAIC,MAAOpC,KAAKU,QACnB7B,EAAI,EAAGA,EAAImB,KAAKU,OAAQ7B,IAAM,CACvC,IAAMsC,EAAInB,KAAKO,QAAS1B,GACxBsD,EAAQtD,GAAMmB,KAAKc,MAAOK,GAC1B,IAAM,IAAI/B,EAAI,EAAGA,EAAIY,KAAKM,EAAGlB,IAAM,CAClC,IAAMI,EAAMxB,EAAEwD,IAAKlC,EAAGF,GAAMpB,EAAEwD,IAAKlC,EAAGF,GAAMY,KAAKuD,MAAM/B,IAAKpC,EAAGP,GAAM,EACrEsD,EAAQtD,IAAOW,GAKjB,IAFA,IAAMqD,EAAIR,YAAKF,GACXW,EAAU,EACJjE,EAAI,EAAGA,EAAIsD,EAAOrD,OAAQD,IACnCiE,GAAWC,IAAKZ,EAAQtD,GAAMgE,GAE/B,IAAMG,EAAQH,EAAIxB,IAAIyB,GACtBX,EAASc,YAAUd,EAAQa,GAC3BN,EAAKpD,GAAM6C,EAAOZ,KAAK,SAAAvD,GAAC,OAAI+E,IAAK/E,MAElC,OAAO0E,EAIR,IADA,IAAIP,EAAS,IAAIC,MAAOpC,KAAKU,QACnB7B,EAAI,EAAGA,EAAImB,KAAKU,OAAQ7B,IAAM,CACvC,IAAMsC,EAAInB,KAAKO,QAAS1B,GACxBsD,EAAQtD,GAAMmB,KAAKc,MAAOK,GAC1B,IAAM,IAAI/B,EAAI,EAAGA,EAAIY,KAAKM,EAAGlB,IAAM,CAClC,IAAMI,EAAMxB,EAAGoB,GAAMY,KAAKuD,MAAM/B,IAAKpC,EAAGP,GACxCsD,EAAQtD,IAAOW,GAKjB,IAFA,IAAMqD,EAAIR,YAAKF,GACXW,EAAU,EACJjE,EAAI,EAAGA,EAAIsD,EAAOrD,OAAQD,IACnCiE,GAAWC,IAAKZ,EAAQtD,GAAMgE,GAE/B,IAAMG,EAAQH,EAAIxB,IAAIyB,GAEtB,OADAX,EAASc,YAAUd,EAAQa,IACbzB,KAAK,SAAAvD,GAAC,OAAI+E,IAAK/E,O,cCpN9B4F,YAAc,qBACd,IAAIC,EAAU,EA0ERC,EAAW,SAAC,GAA+C,IAA7C9F,EAA4C,EAA5CA,EAAGM,EAAyC,EAAzCA,EAAGC,EAAsC,EAAtCA,KAAMC,EAAgC,EAAhCA,aAAcuF,EAAkB,EAAlBA,YAC7C,IACC,IADG,GACaA,EAAcpE,IAAsBtB,KACHL,EAAGM,EAAGC,EAAMC,GAArDC,EAFL,EAEKA,OAAQC,EAFb,EAEaA,WAEhB,MAAO,CACNsF,OC/CH,SAAqBhG,EAAGM,GACvB,GAAKd,IAAcQ,GAClBA,EAAIyB,IAASzB,QACP,IAAMuE,IAAcvE,GAE1B,MAAM,IAAIH,UADE,8FAAgGG,EAAI,KAGjH,IAAM8B,IAAaxB,GAClB,MAAM,IAAIT,UAAW,2EAA6ES,EAAI,KAGvG,OADY,IAAI8B,EAAapC,EAAGM,GDmChB2F,CAAUxF,EAHtB,EAEyBiB,SAI3BhB,cAEA,MAAQwF,GACT,MAAO,KAiBHC,E,kDACL,WAAaC,GAAS,IAAD,sBACpB,cAAOA,GADa,+CA4BF,WAClB,EAAKA,MAAMC,UAAW,EAAKC,MAAMN,OAAQH,MA1BzCA,GAAW,EAHS,IAIZ7F,EAA0CoG,EAA1CpG,EAAGM,EAAuC8F,EAAvC9F,EAAGC,EAAoC6F,EAApC7F,KAAMC,EAA8B4F,EAA9B5F,aAAcuF,EAAgBK,EAAhBL,YAJd,OAKpB,EAAKO,MAAL,2BACIR,EAAS,CAAE9F,IAAGM,IAAGC,OAAMC,eAAcuF,iBACrCK,GAPgB,E,0CAgCrB,WAAU,IAAD,EACuBpE,KAAKsE,MAA5BN,EADA,EACAA,OAAQtF,EADR,EACQA,WACR6F,EAAMvE,KAAKoE,MAAXG,EACR,OAAMP,EAIL,yBAAKQ,MAAO,CAAEC,UAAW,OAAQC,MAAO,SACvC,0BAAMC,UAAU,SAAUJ,EAAE,2BAA4B,CAAEjG,EAAG0B,KAAKoE,MAAM9F,EAAGsG,QAASf,KAzInE,SAAEnF,EAAYsF,EAAQxF,EAAc+F,GACxD,OACC,6BACC,0BAAMI,UAAU,SAASJ,EAAE,iBAA3B,KACA,kBAAC,IAAD,CAAOM,UAAQ,EAACC,KAAK,MACpB,+BACC,4BACEd,EAAOzD,QAAQgB,KAAK,SAAEvD,EAAGsB,GAAL,OAAY,wBAAIyF,IAAKzF,GAAItB,QAGhD,+BACC,4BACEgG,EAAOzD,QAAQgB,KAAK,SAAEvD,EAAGsB,GAAL,OAAY,wBAAIyF,IAAKzF,GAAIyD,IAAIiB,EAAOlD,MAAO9C,IAAKgH,QAAS,UAIjF,0BAAML,UAAU,SAASJ,EAAE,gBAA3B,KACC7F,EAAW6C,KAAK,SAAE0D,EAAM3F,GACxB,OAAKN,IAAUR,EAAcyG,GACnB,kBAAC,IAAD,CAAOJ,UAAQ,EAACC,KAAK,KAAKC,IAAKzF,GACvC,+BACC,4BACC,4BAAK2F,GACJjB,EAAOzD,QAAQgB,KAAK,SAAEvD,EAAGsB,GAAL,OAAY,wBAAIyF,IAAKzF,GAAItB,QAGhD,+BACC,4BACC,4BAAKuG,EAAE,SACNP,EAAOzD,QAAQgB,KAAK,SAAE2D,EAAGrG,GACzB,OAAO,wBAAIkG,IAAG,UAAKzF,EAAL,YAAUT,IAAMmF,EAAOjD,GAAGS,IAAKlC,EAAGT,GAAImG,QAAS,QAG/D,4BACC,4BAAKT,EAAE,OACNP,EAAOzD,QAAQgB,KAAK,SAAE2D,EAAGrG,GACzB,OAAO,wBAAIkG,IAAG,UAAKzF,EAAL,YAAUT,IAAMmF,EAAO/C,MAAMO,IAAKlC,EAAGT,GAAImG,QAAS,UAM5D,kBAAC,IAAD,CAAOH,UAAQ,EAACC,KAAK,KAAKC,IAAKzF,GACvC,+BACC,4BACC,4BAAK2F,GACJjB,EAAOzD,QAAQgB,KAAK,SAAEvD,EAAGsB,GAAL,OAAY,wBAAIyF,IAAKzF,GAAItB,QAGhD,+BACC,4BACC,4BAAKuG,EAAE,QACNP,EAAOzD,QAAQgB,KAAK,SAAE2D,EAAGrG,GACzB,OAAO,wBAAIkG,IAAG,UAAKzF,EAAL,YAAUT,IAAMmF,EAAOjD,GAAGS,IAAKlC,EAAGT,GAAImG,QAAS,QAG/D,4BACC,4BAAKT,EAAE,OACNP,EAAOzD,QAAQgB,KAAK,SAAE2D,EAAGrG,GACzB,OAAO,wBAAIkG,IAAG,UAAKzF,EAAL,YAAUT,KAAO,EAAEmF,EAAOjD,GAAGS,IAAKlC,EAAGT,IAAKmG,QAAS,cA+EpEG,CAAczG,EAAYsF,EAAQhE,KAAKoE,MAAM5F,aAAc+F,GAC3DvE,KAAKoE,MAAMC,UAAY,kBAAC,IAAD,CAASe,QAASb,EAAE,iCAC3C,kBAACc,EAAA,EAAD,CAAQC,QAAQ,YAAYR,KAAK,KAAKS,QAASvF,KAAKwF,kBAAoBjB,EAAE,0BAC9D,MARP,kBAACkB,EAAA,EAAD,CAAOH,QAAQ,UAAUf,EAAE,0B,uCAzBpC,SAAiCmB,EAAWC,GAC3C,GACCD,EAAUnH,OAASoH,EAAUpH,MAC7BmH,EAAUlH,eAAiBmH,EAAUnH,cACrCkH,EAAU1H,IAAM2H,EAAU3H,GAC1B0H,EAAUpH,IAAMqH,EAAUrH,GAC1BoH,EAAU3B,cAAgB4B,EAAU5B,YACnC,CAAC,IACM/F,EAA0C0H,EAA1C1H,EAAGM,EAAuCoH,EAAvCpH,EAAGC,EAAoCmH,EAApCnH,KAAMC,EAA8BkH,EAA9BlH,aAAcuF,EAAgB2B,EAAhB3B,YAClC,OAAO,2BACHD,EAAS,CAAE9F,IAAGM,IAAGC,OAAMC,eAAcuF,iBACrC2B,GAGL,OAAO,S,GA1BgBE,aAsDzBzB,EAAW0B,aAAe,CACzB9B,aAAa,EACbM,UAAW,MAkBGyB,sBAAiB,oBAAjBA,CAAwC3B,I,iCElMvD,8BA+CelB,IAhCf,SAAmBN,EAAK3E,GACvB,IAAM+H,EAAQjG,IAAa9B,GAC3B,IAAM8B,IAAa6C,GAClB,MAAM,IAAI9E,UAAW,0DAA4D8E,EAAM,MAExF,IAAMoD,IAAU3H,sBAAUJ,GACzB,MAAM,IAAIH,UAAW,gGAAkGG,EAAI,MAE5H,IAAMgI,EAAMrD,EAAI7D,OACVqE,EAAM,IAAIf,MAAO4D,GAGvB,GAAKD,EAAQ,CACZ,GAAKC,IAAQhI,EAAEc,OACd,MAAM,IAAImH,MAAO,kGAElB,IAAM,IAAI3G,EAAI,EAAGA,EAAI0G,EAAK1G,IACzB6D,EAAK7D,GAAMqD,EAAKrD,GAAMtB,EAAGsB,QAK1B,IAAM,IAAIA,EAAI,EAAGA,EAAI0G,EAAK1G,IACzB6D,EAAK7D,GAAMqD,EAAKrD,GAAMtB,EAGxB,OAAOmF","file":"static/js/NaiveBayes.fc3be513.chunk.js","sourcesContent":["/**\n* @license Apache-2.0\n*\n* Copyright (c) 2018 The Stdlib Authors.\n*\n* Licensed under the Apache License, Version 2.0 (the \"License\");\n* you may not use this file except in compliance with the License.\n* You may obtain a copy of the License at\n*\n*    http://www.apache.org/licenses/LICENSE-2.0\n*\n* Unless required by applicable law or agreed to in writing, software\n* distributed under the License is distributed on an \"AS IS\" BASIS,\n* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n* See the License for the specific language governing permissions and\n* limitations under the License.\n*/\n'use strict';\n/**\n* Test if a value is an array of arrays.\n*\n* @module @stdlib/assert/is-array-array\n*\n* @example\n* var isArrayArray = require( '@stdlib/assert/is-array-array' );\n*\n* var bool = isArrayArray( [ [], [] ] );\n* // returns true\n*\n* bool = isArrayArray( [ {}, {} ] );\n* // returns false\n*\n* bool = isArrayArray( [] );\n* // returns false\n*/\n// MODULES //\n\nvar isArrayArray = require('./main.js'); // EXPORTS //\n\n\nmodule.exports = isArrayArray;","export default function _readOnlyError(name) {\n  throw new TypeError(\"\\\"\" + name + \"\\\" is read-only\");\n}","/**\n* @license Apache-2.0\n*\n* Copyright (c) 2018 The Stdlib Authors.\n*\n* Licensed under the Apache License, Version 2.0 (the \"License\");\n* you may not use this file except in compliance with the License.\n* You may obtain a copy of the License at\n*\n*    http://www.apache.org/licenses/LICENSE-2.0\n*\n* Unless required by applicable law or agreed to in writing, software\n* distributed under the License is distributed on an \"AS IS\" BASIS,\n* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n* See the License for the specific language governing permissions and\n* limitations under the License.\n*/\n'use strict'; // MODULES //\n\nvar arrayfun = require('@stdlib/assert/tools/array-function');\n\nvar isArray = require('@stdlib/assert/is-array'); // MAIN //\n\n/**\n* Tests if a value is an array of arrays.\n*\n* @name isArrayArray\n* @type {Function}\n* @param {*} value - value to test\n* @returns {boolean} boolean indicating whether a value is an array of arrays\n*\n* @example\n* var bool = isArrayArray( [ [], [] ] );\n* // returns true\n*\n* bool = isArrayArray( [ {}, {} ] );\n* // returns false\n*\n* bool = isArrayArray( [] );\n* // returns false\n*/\n\n\nvar isArrayArray = arrayfun(isArray); // EXPORTS //\n\nmodule.exports = isArrayArray;","// MODULES //\n\nimport contains from '@stdlib/assert/contains';\nimport ndarray from '@stdlib/ndarray/array';\nimport { isPrimitive as isNumber } from '@stdlib/assert/is-number';\nimport isUndefinedOrNull from '@stdlib/assert/is-undefined-or-null';\nimport isnan from '@stdlib/assert/is-nan';\nimport isArray from '@stdlib/assert/is-array';\nimport extractCategoriesFromValues from '@isle-project/utils/extract-categories-from-values';\n\n\n// FUNCTIONS //\n\nfunction isMissing( x ) {\n\treturn isnan( x ) || isUndefinedOrNull( x );\n}\n\nfunction isNonMissingNumber( x ) {\n\treturn isNumber( x ) && !isnan( x );\n}\n\n\n// MAIN //\n\nexport function designMatrix( x, y, data, quantitative ) {\n\tlet matrix = [];\n\tconst predictors = [];\n\tconst hash = {};\n\tif ( !isArray( x ) ) {\n\t\tx = [ x ];\n\t}\n\tfor ( let j = 0; j < x.length; j++ ) {\n\t\tconst values = data[ x[ j ] ];\n\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\tpredictors.push( x[ j ] );\n\t\t} else {\n\t\t\tconst categories = extractCategoriesFromValues( values, x[ j ] );\n\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\tpredictors.push( `${x[ j ]}_${categories[ k ]}` );\n\t\t\t}\n\t\t\thash[ x[ j ] ] = categories;\n\t\t}\n\t}\n\tconst nobs = data[ x[ 0 ] ].length;\n\tfor ( let i = 0; i < nobs; i++ ) {\n\t\tconst row = [];\n\t\tfor ( let j = 0; j < x.length; j++ ) {\n\t\t\tconst values = data[ x[ j ] ];\n\t\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\t\trow.push( values[ i ] );\n\t\t\t} else {\n\t\t\t\tconst categories = hash[ x[ j ] ];\n\t\t\t\tconst val = values[ i ];\n\t\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\t\trow.push( ( val === categories[ k ] ) ? 1 : 0 );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tmatrix.push( row );\n\t}\n\tmatrix = ndarray( matrix );\n\tconst yvalues = data[ y ];\n\treturn { matrix, predictors, yvalues };\n}\n\nexport function designMatrixMissing( x, y, data, quantitative ) {\n\tlet matrix = [];\n\tconst predictors = [];\n\tconst hash = {};\n\tif ( !isArray( x ) ) {\n\t\tx = [ x ];\n\t}\n\tfor ( let j = 0; j < x.length; j++ ) {\n\t\tconst values = data[ x[ j ] ];\n\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\tpredictors.push( x[ j ] );\n\t\t} else {\n\t\t\tconst categories = extractCategoriesFromValues( values, x[ j ] );\n\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\tpredictors.push( `${x[ j ]}_${categories[ k ]}` );\n\t\t\t}\n\t\t\thash[ x[ j ] ] = categories;\n\t\t}\n\t}\n\tconst nobs = data[ x[ 0 ] ].length;\n\tconst yvalues = [];\n\tfor ( let i = 0; i < nobs; i++ ) {\n\t\tconst row = [];\n\t\tlet missing = false;\n\t\tfor ( let j = 0; j < x.length; j++ ) {\n\t\t\tconst values = data[ x[ j ] ];\n\t\t\tif ( contains( quantitative, x[ j ] ) ) {\n\t\t\t\tif ( isNonMissingNumber( values[ i ] ) ) {\n\t\t\t\t\trow.push( values[ i ] );\n\t\t\t\t} else {\n\t\t\t\t\tmissing = true;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst categories = hash[ x[ j ] ];\n\t\t\t\tconst val = values[ i ];\n\t\t\t\tif ( isMissing( val ) ) {\n\t\t\t\t\tmissing = true;\n\t\t\t\t} else {\n\t\t\t\t\tfor ( let k = 0; k < categories.length; k++ ) {\n\t\t\t\t\t\trow.push( ( val === categories[ k ] ) ? 1 : 0 );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif ( isMissing( data[ y ][ i ] ) ) {\n\t\t\tmissing = true;\n\t\t}\n\t\tif ( !missing ) {\n\t\t\tmatrix.push( row );\n\t\t\tyvalues.push( data[ y ][ i ] );\n\t\t}\n\t}\n\tmatrix = ndarray( matrix );\n\treturn { matrix, predictors, yvalues };\n}\n","// MODULES //\n\nimport isArrayLike from '@stdlib/assert/is-array-like';\n\n\n// MAIN //\n\n/**\n* Calculates the mean accuracy of the given test data and labels.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {number} mean accuracy\n*/\nfunction score( x, y ) {\n\tif ( !isArrayLike( x ) ) {\n\t\tthrow new TypeError( 'invalid argument. First argument must be a matrix or array of test data. Value: `' + x + '`' );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid argument. Second argument must be an array of labels for the test data. Value: `' + y + '`' );\n\t}\n\tconst yhat = this.predict( x ); // eslint-disable-line @babel/no-invalid-this\n\tconst n = y.length;\n\tlet accuracy = 0;\n\tfor ( let i = 0; i < n; i++ ) {\n\t\tif ( yhat[ i ] === y[ i ] ) {\n\t\t\taccuracy += 1;\n\t\t}\n\t}\n\taccuracy /= n;\n\treturn accuracy;\n}\n\n\n// EXPORTS //\n\nexport default score;\n","// MODULES //\n\nimport uniq from 'uniq';\nimport ndarray from '@stdlib/ndarray/array';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport exp from '@stdlib/math/base/special/exp';\nimport ln from '@stdlib/math/base/special/ln';\nimport pow from '@stdlib/math/base/special/pow';\nimport PI from '@stdlib/constants/math/float64-pi';\nimport mean from '@isle-project/utils/statistic/mean';\nimport stdev from '@isle-project/utils/statistic/stdev';\nimport max from '@isle-project/utils/statistic/max';\nimport subtract from '@isle-project/utils/subtract';\n\n\n// MAIN //\n\n/**\n* Naive Bayes fitting object constructor for normal distribution.\n*\n* @constructor\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {GaussianFit} GaussianFit instance\n*/\nfunction GaussianFit( x, y ) {\n\tthis.n = x.shape[ 0 ];\n\tthis.p = x.shape[ 1 ];\n\n\tthis.classes = uniq( y.slice() );\n\tthis.nclass = this.classes.length;\n\n\tthis.fitGaussian( x, y );\n}\n\nGaussianFit.prototype.score = require( './score.js' );\n\n\n/**\n* Fit the data under the assumption that p(x_i|c) follows a normal distribution.\n*\n* ## Notes\n*\n* -   Assigns prior and conditional probabilities of BayesFit instance.\n*\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {void}\n*/\nGaussianFit.prototype.fitGaussian = function fitGaussian( x, y ) {\n\tthis.prior = {};\n\tconst shape = [ this.p, this.nclass ];\n\tthis.mu = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tthis.sigma = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tfor ( let i = 0; i < this.nclass; i++ ) {\n\t\tconst ids = [];\n\t\tconst c = this.classes[ i ];\n\t\tfor ( let j = 0; j < this.n; j++ ) {\n\t\t\tif ( y[ j ] === c ) {\n\t\t\t\tids.push( j );\n\t\t\t}\n\t\t}\n\t\tconst nc = ids.length;\n\t\tthis.prior[ c ] = ln( nc / this.n );\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst vals = ids.map( i => x.get( i, j ) );\n\t\t\tconst mu = mean( vals );\n\t\t\tconst sigma = stdev( vals );\n\t\t\tthis.mu.set( j, i, mu );\n\t\t\tthis.sigma.set( j, i, sigma );\n\t\t}\n\t}\n};\n\n/**\n* Calculate p(X=x,C=i), i.e. the joint probability of observation x and class i.\n*\n* @param {Array} x - new observation\n* @param {number} i - class indicator\n* @returns {number} log probability\n*/\nGaussianFit.prototype.calcGaussianProb = function calcGaussianProb( x, i ) {\n\tconst c = this.classes[ i ];\n\tlet res = this.prior[ c ];\n\n\tfor ( let j = 0; j < this.p; j++ ) {\n\t\tconst sigma = this.sigma.get( j, i );\n\t\tconst s2 = sigma*sigma;\n\t\tconst mu = this.mu.get( j, i );\n\t\tconst val = ( -0.5 * ln( 2 * PI * s2 ) ) - ( pow( x[ j ] - mu, 2 ) / s2 );\n\t\tres += val;\n\t}\n\treturn res;\n};\n\n/**\n* Predict class membership for one new observation.\n*\n* @param {Array} x - new observation\n* @returns {(number|string)} predicted class membership\n*/\nGaussianFit.prototype.predictOne = function predictOne( x ) {\n\tconst nClasses = this.classes.length;\n\tconst logLik = new Array( nClasses );\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tlogLik[ i ] = this.calcGaussianProb( x, i );\n\t}\n\tlet max = logLik[ 0 ];\n\tlet argmax = this.classes[ 0 ];\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst val = logLik[ i ];\n\t\tif ( val > max ) {\n\t\t\tmax = val;\n\t\t\targmax = this.classes[ i ];\n\t\t}\n\t}\n\treturn argmax;\n};\n\n/**\n* Predict class membership for new observation(s).\n*\n* @param {(Matrix|Array)} x - new observation(s)\n* @returns {Array} array of predicted class memberships\n*/\nGaussianFit.prototype.predict = function predict( x ) {\n\tconst nClasses = this.classes.length;\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst [ nrow, ncol ] = x.shape;\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tconst logLik = new Array( nClasses );\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst arr = new Array( ncol );\n\t\t\t\tfor ( let k = 0; k < ncol; k++ ) {\n\t\t\t\t\tarr[ k ] = x.get( i, k );\n\t\t\t\t}\n\t\t\t\tlogLik[ j ] = this.calcGaussianProb( arr, j );\n\t\t\t}\n\t\t\tlet max = logLik[ 0 ];\n\t\t\tlet argmax = this.classes[ 0 ];\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst val = logLik[ j ];\n\t\t\t\tif ( val > max ) {\n\t\t\t\t\tmax = val;\n\t\t\t\t\targmax = this.classes[ j ];\n\t\t\t\t}\n\t\t\t}\n\t\t\tret[ i ] = argmax;\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Only one new observation:\n\treturn this.predictOne( x );\n};\n\n/**\n* Calculates class membership probabilities.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @returns {Array} class probabilities\n*/\nGaussianFit.prototype.predictProbs = function predictProbs( x ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst [ nrow, ncol ] = x.shape;\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tlet logLik = new Array( this.nclass );\n\t\t\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\t\t\tconst arr = new Array( ncol );\n\t\t\t\tfor ( let k = 0; k < ncol; k++ ) {\n\t\t\t\t\tarr[ k ] = x.get( i, k );\n\t\t\t\t}\n\t\t\t\tlogLik[ j ] = this.calcGaussianProb( arr, j );\n\t\t\t}\n\t\t\tconst a = max( logLik );\n\t\t\tlet summand = 0;\n\t\t\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\t\t\tsummand += exp( logLik[ j ] - a );\n\t\t\t}\n\t\t\tconst denom = a + ln( summand );\n\t\t\tlogLik = subtract( logLik, denom );\n\t\t\tret[ i ] = logLik.map( x => exp( x ) );\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Create prediction for a single observation:\n\tconst logLik = new Array( this.nclass );\n\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\tlogLik[ j ] = this.calcGaussianProb( x, j );\n\t}\n\tconst a = max( logLik );\n\tlet summand = 0;\n\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\tsummand += exp( logLik[ j ] - a );\n\t}\n\tconst denom = a + ln( summand );\n\tlogLik = subtract( logLik, denom );\n\treturn logLik.map( x => exp( x ) );\n};\n\n\n// EXPORTS //\n\nexport default GaussianFit;\n","// MODULES //\n\nimport uniq from 'uniq';\nimport ndarray from '@stdlib/ndarray/array';\nimport max from '@isle-project/utils/statistic/max';\nimport subtract from '@isle-project/utils/subtract';\nimport exp from '@stdlib/math/base/special/exp';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport ln from '@stdlib/math/base/special/ln';\n\n\n// FUNCTIONS //\n\nconst sum = ( arr ) => {\n\tlet out = 0;\n\tfor ( let i = 0; i < arr.length; i++ ) {\n\t\tout += arr[ i ];\n\t}\n\treturn out;\n};\n\n\n// MAIN //\n\n/**\n* Naive Bayes fitting object constructor for multinomial distribution.\n*\n* @constructor\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @param {number} alpha - Laplace smoothing parameter\n* @returns {MultinomialFit} MultinomialFit instance\n*/\nfunction MultinomialFit( x, y, alpha ) {\n\tthis.n = x.shape[ 0 ];\n\tthis.p = x.shape[ 1 ];\n\n\tthis.classes = uniq( y.slice() );\n\tthis.nclass = this.classes.length;\n\tthis.alpha = alpha;\n\n\tthis.fitMultinomial( x, y );\n}\n\nMultinomialFit.prototype.score = require( './score.js' );\n\n\n/**\n* Fit the data under the assumption that p(x_i|c) follows a multinomial distribution.\n*\n* ## Notes\n*\n* -   Assigns prior and conditional probabilities of BayesFit instance.\n*\n* @param {Matrix} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {Void}\n*/\nMultinomialFit.prototype.fitMultinomial = function fitMultinomial( x, y ) {\n\tconst prior = {};\n\tconst shape = [ this.p, this.nclass ];\n\tconst cprob = ndarray( new Float64Array( shape[0]*shape[1] ), { 'shape': shape } );\n\tfor ( let i = 0; i < this.nclass; i++ ) {\n\t\tconst ids = [];\n\t\tconst counts = new Int32Array( this.p );\n\t\tconst c = this.classes[ i ];\n\t\tfor ( let j = 0; j < this.n; j++ ) {\n\t\t\tif ( y[ j ] === c ) {\n\t\t\t\tids.push( j );\n\t\t\t}\n\t\t}\n\t\tconst nc = ids.length;\n\t\tprior[ c ] = ln( nc / this.n );\n\t\tlet totalCount = 0;\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst vals = ids.map( i => x.get( i, j ) );\n\t\t\tcounts[ j ] = sum( vals );\n\t\t\ttotalCount += counts[ j ];\n\t\t}\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst val = ln( counts[ j ] + this.alpha ) - ln( totalCount + this.p * this.alpha );\n\t\t\tcprob.set( j, i, val );\n\t\t}\n\t}\n\tthis.prior = prior;\n\tthis.cprob = cprob;\n};\n\n/**\n* Calculates multinomial probability.\n*\n* @param {Array} x - new observation\n* @param {number} i - class indicator\n* @param {number} j - variable indicator\n* @returns {number} probability\n*/\nMultinomialFit.prototype.calcMultinomProb = function calcMultinomProb( x, i, j ) {\n\tconst c = this.classes[ i ];\n\tlet res = this.prior[ c ];\n\tfor ( j = 0; j < this.p; j++ ) {\n\t\tconst val = x[ j ] ? x[ j ] * this.cprob.get( j, i ) : 0;\n\t\tres += val;\n\t}\n\treturn res;\n};\n\n/**\n* Predict class membership for one new observation.\n*\n* @param {Array} x - new observation\n* @returns {(number|string)} predicted class membership\n*/\nMultinomialFit.prototype.predictOne = function predictOne( x ) {\n\tconst nClasses = this.classes.length;\n\tconst logLik = new Array( nClasses );\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst c = this.classes[ i ];\n\t\tlogLik[ i ] = this.prior[ c ];\n\t\tfor ( let j = 0; j < this.p; j++ ) {\n\t\t\tconst val = x[ j ] ? x[ j ] * this.cprob.get( j, i ) : 0;\n\t\t\tlogLik[ i ] += val;\n\t\t}\n\t}\n\tlet max = logLik[ 0 ];\n\tlet argmax = this.classes[ 0 ];\n\tfor ( let i = 0; i < nClasses; i++ ) {\n\t\tconst val = logLik[ i ];\n\t\tif ( val > max ) {\n\t\t\tmax = val;\n\t\t\targmax = this.classes[ i ];\n\t\t}\n\t}\n\treturn argmax;\n};\n\n/**\n* Predict class membership for new observation(s).\n*\n* @param {(Matrix|Array)} x - new observation(s)\n* @returns {Array} array of predicted class memberships\n*/\nMultinomialFit.prototype.predict = function predict( x ) {\n\tconst nClasses = this.classes.length;\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst ret = [];\n\t\tconst nrow = x.shape[ 0 ];\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tconst logLik = new Array( nClasses );\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\tconst c = this.classes[ j ];\n\t\t\t\tlogLik[ j ] = this.prior[ c ];\n\t\t\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\t\t\tconst val = x.get( i, k ) ? x.get( i, k ) * this.cprob.get( k, j ) : 0;\n\t\t\t\t\tlogLik[ j ] += val;\n\t\t\t\t}\n\t\t\t}\n\t\t\tlet max = logLik[ 0 ];\n\t\t\tlet argmax = this.classes[ 0 ];\n\t\t\tfor ( let j = 0; j < nClasses; j++ ) {\n\t\t\t\t\tconst val = logLik[ j ];\n\t\t\t\t\tif ( val > max ) {\n\t\t\t\t\t\tmax = val;\n\t\t\t\t\t\targmax = this.classes[ j ];\n\t\t\t\t\t}\n\t\t\t}\n\t\t\tret[ i ] = argmax;\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Only one new observation:\n\treturn this.predictOne( x );\n};\n\n/**\n* Calculates class membership probabilities.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @returns {Array} class probabilities\n*/\nMultinomialFit.prototype.predictProbs = function predictProbs( x ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t}\n\t// Case A: Predictions for multiple observations:\n\tif ( isMatrixLike( x ) ) {\n\t\tconst nrow = x.shape[ 0 ];\n\t\tconst ret = new Array( nrow );\n\t\tfor ( let i = 0; i < nrow; i++ ) {\n\t\t\tlet logLik = new Array( this.nclass );\n\t\t\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\t\t\tconst c = this.classes[ j ];\n\t\t\t\tlogLik[ j ] = this.prior[ c ];\n\t\t\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\t\t\tconst val = x.get( i, k ) ? x.get( i, k ) * this.cprob.get( k, j ) : 0;\n\t\t\t\t\tlogLik[ j ] += val;\n\t\t\t\t}\n\t\t\t}\n\t\t\tconst a = max( logLik );\n\t\t\tlet summand = 0;\n\t\t\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\t\t\tsummand += exp( logLik[ j ] - a );\n\t\t\t}\n\t\t\tconst denom = a + ln( summand );\n\t\t\tlogLik = subtract( logLik, denom );\n\t\t\tret[ i ] = logLik.map( x => exp( x ) );\n\t\t}\n\t\treturn ret;\n\t}\n\t// Case B: Create prediction for a single observation:\n\tlet logLik = new Array( this.nclass );\n\tfor ( let j = 0; j < this.nclass; j++ ) {\n\t\tconst c = this.classes[ j ];\n\t\tlogLik[ j ] = this.prior[ c ];\n\t\tfor ( let k = 0; k < this.p; k++ ) {\n\t\t\tconst val = x[ k ] * this.cprob.get( k, j );\n\t\t\tlogLik[ j ] += val;\n\t\t}\n\t}\n\tconst a = max( logLik );\n\tlet summand = 0;\n\tfor ( let j = 0; j < logLik.length; j++ ) {\n\t\tsummand += exp( logLik[ j ] - a );\n\t}\n\tconst denom = a + ln( summand );\n\tlogLik = subtract( logLik, denom );\n\treturn logLik.map( x => exp( x ) );\n};\n\n\n// EXPORTS //\n\nexport default MultinomialFit;\n","// MODULES //\n\nimport React, { Component } from 'react';\nimport PropTypes from 'prop-types';\nimport { withTranslation } from 'react-i18next';\nimport Alert from 'react-bootstrap/Alert';\nimport Button from 'react-bootstrap/Button';\nimport Table from '@isle-project/components/table';\nimport contains from '@stdlib/assert/contains';\nimport exp from '@stdlib/math/base/special/exp';\nimport Tooltip from '@isle-project/components/tooltip';\nimport { addResources } from '@isle-project/locales';\nimport { gaussian } from './naive_bayes.js';\nimport { designMatrix, designMatrixMissing } from './design_matrix.js';\n\n\n// VARIABLES //\n\naddResources( 'StatisticalModels' );\nlet COUNTER = 0;\n\n\n// FUNCTIONS //\n\nconst summaryTable = ( predictors, result, quantitative, t ) => {\n\treturn (\n\t\t<div>\n\t\t\t<span className=\"title\">{t('apriori-probs')}:</span>\n\t\t\t<Table bordered size=\"sm\">\n\t\t\t\t<thead>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t</tr>\n\t\t\t\t</thead>\n\t\t\t\t<tbody>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{exp(result.prior[ x ]).toFixed( 3 )}</th>)}\n\t\t\t\t\t</tr>\n\t\t\t\t</tbody>\n\t\t\t</Table>\n\t\t\t<span className=\"title\">{t('conditionals')}:</span>\n\t\t\t{predictors.map( ( pred, i ) => {\n\t\t\t\tif ( contains( quantitative, pred ) ) {\n\t\t\t\t\treturn ( <Table bordered size=\"sm\" key={i} >\n\t\t\t\t\t\t<thead>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{pred}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t</thead>\n\t\t\t\t\t\t<tbody>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{t('mean')}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.mu.get( i, j ).toFixed( 6 )}</td>;\n\t\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t\t<th>{t('sd')}</th>\n\t\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.sigma.get( i, j ).toFixed( 6 )}</td>;\n\t\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t</tbody>\n\t\t\t\t\t</Table> );\n\t\t\t\t}\n\t\t\t\treturn ( <Table bordered size=\"sm\" key={i} >\n\t\t\t\t\t<thead>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{pred}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( x, i ) => <th key={i}>{x}</th>)}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t</thead>\n\t\t\t\t\t<tbody>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{t('yes')}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{result.mu.get( i, j ).toFixed( 3 )}</td>;\n\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t<tr>\n\t\t\t\t\t\t\t<th>{t('no')}</th>\n\t\t\t\t\t\t\t{result.classes.map( ( _, j ) => {\n\t\t\t\t\t\t\t\treturn <td key={`${i}-${j}`}>{(1-result.mu.get( i, j )).toFixed( 3 )}</td>;\n\t\t\t\t\t\t\t})}\n\t\t\t\t\t\t</tr>\n\t\t\t\t\t</tbody>\n\t\t\t\t</Table> );\n\t\t\t})}\n\t\t</div>\n\t);\n};\n\nconst fitModel = ({ x, y, data, quantitative, omitMissing }) => {\n\ttry {\n\t\tconst designM = omitMissing ? designMatrixMissing : designMatrix;\n\t\tconst { matrix, predictors, yvalues } = designM( x, y, data, quantitative );\n\t\tconst result = gaussian( matrix, yvalues );\n\t\treturn {\n\t\t\tresult,\n\t\t\tpredictors\n\t\t};\n\t} catch ( error ) {\n\t\treturn {};\n\t}\n};\n\n\n// MAIN //\n\n/**\n* Naive Bayes assuming that the predictors given the class membership follow a normal distribution.\n*\n* @property {Object} data - object of value arrays\n* @property {string} y - outcome variable\n* @property {Array<string>} x - one or more predictor variables\n* @property {Array<string>} quantitative - array of variables in `data` that are `quantitative`\n* @property {boolean} omitMissing - controls whether to omit missing values\n* @property {Function} onPredict - callback invoked with predictions and residuals after model fitting\n*/\nclass NaiveBayes extends Component {\n\tconstructor( props ) {\n\t\tsuper( props );\n\n\t\tCOUNTER += 1;\n\t\tconst { x, y, data, quantitative, omitMissing } = props;\n\t\tthis.state = {\n\t\t\t...fitModel({ x, y, data, quantitative, omitMissing }),\n\t\t\t...props\n\t\t};\n\t}\n\n\tstatic getDerivedStateFromProps( nextProps, prevState ) {\n\t\tif (\n\t\t\tnextProps.data !== prevState.data ||\n\t\t\tnextProps.quantitative !== prevState.quantitative ||\n\t\t\tnextProps.x !== prevState.x ||\n\t\t\tnextProps.y !== prevState.y ||\n\t\t\tnextProps.omitMissing !== prevState.omitMissing\n\t\t) {\n\t\t\tconst { x, y, data, quantitative, omitMissing } = nextProps;\n\t\t\treturn {\n\t\t\t\t...fitModel({ x, y, data, quantitative, omitMissing }),\n\t\t\t\t...nextProps\n\t\t\t};\n\t\t}\n\t\treturn null;\n\t}\n\n\thandlePrediction = () => {\n\t\tthis.props.onPredict( this.state.result, COUNTER );\n\t}\n\n\trender() {\n\t\tconst { result, predictors } = this.state;\n\t\tconst { t } = this.props;\n\t\tif ( !result ) {\n\t\t\treturn <Alert variant=\"danger\">{t('missing-attributes')}</Alert>;\n\t\t}\n\t\treturn (\n\t\t\t<div style={{ overflowX: 'auto', width: '100%' }}>\n\t\t\t\t<span className=\"title\" >{t('naive-bayes-for-response', { y: this.props.y, counter: COUNTER })}</span>\n\t\t\t\t{summaryTable( predictors, result, this.props.quantitative, t )}\n\t\t\t\t{this.props.onPredict ? <Tooltip tooltip={t('use-model-to-predict-tooltip')} >\n\t\t\t\t\t<Button variant=\"secondary\" size=\"sm\" onClick={this.handlePrediction} >{t('use-model-to-predict')}</Button>\n\t\t\t\t</Tooltip> : null}\n\t\t\t</div>\n\t\t);\n\t}\n}\n\n\n// PROPERTIES //\n\nNaiveBayes.defaultProps = {\n\tomitMissing: false,\n\tonPredict: null\n};\n\nNaiveBayes.propTypes = {\n\tdata: PropTypes.object.isRequired,\n\ty: PropTypes.string.isRequired,\n\tx: PropTypes.oneOfType([\n\t\tPropTypes.arrayOf( PropTypes.string ),\n\t\tPropTypes.string\n\t]).isRequired,\n\tquantitative: PropTypes.arrayOf( PropTypes.string ).isRequired,\n\tomitMissing: PropTypes.bool,\n\tonPredict: PropTypes.func\n};\n\n\n// EXPORTS //\n\nexport default withTranslation( 'StatisticalModels' )( NaiveBayes );\n","// MODULES //\n\nimport ndarray from '@stdlib/ndarray/array';\nimport hasOwnProperty from '@stdlib/assert/has-own-property';\nimport isArrayArray from '@stdlib/assert/is-array-array';\nimport isArrayLike from '@stdlib/assert/is-array-like';\nimport isMatrixLike from '@stdlib/assert/is-matrix-like';\nimport { isPrimitive as isNumber } from '@stdlib/assert/is-number';\nimport GaussianFit from './gaussian.js';\nimport MultinomialFit from './multinomial.js';\n\n\n// MAIN //\n\n/**\n* Fits a multinomial naive Bayes model.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @param {Object} [opts] - function options\n* @param {number} [opts.alpha] - Laplace smoothing parameter\n* @returns {MultinomialFit} MultinomialFit instance\n*/\nfunction multinomNB( x, y, opts ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t} else if ( !isMatrixLike( x ) ) {\n\t\tconst msg = 'invalid input argument. The first argument must be a matrix or an array-of-arrays. Value: `' + x + '`';\n\t\tthrow new TypeError( msg );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid input argument. The second argument must be array-like. Value: `' + y + '`' );\n\t}\n\tif ( arguments > 2 ) {\n\t\tif ( hasOwnProperty( opts, 'alpha' ) ) {\n\t\t\tif ( !isNumber( opts.alpha ) ) {\n\t\t\t\tthrow new TypeError( 'invalid option. Laplace smoothing option must be a number primitive. Option: `' + opts.alpha + '`.' );\n\t\t\t}\n\t\t}\n\t}\n\tconst alpha = opts.alpha || 1;\n\tconst fit = new MultinomialFit( x, y, alpha );\n\treturn fit;\n}\n\n/**\n* Fits a Gaussian naive Bayes model.\n*\n* @param {(Matrix|Array)} x - design matrix\n* @param {Array} y - vector of class memberships\n* @returns {GaussianFit} model fit\n*/\nfunction gaussianNB( x, y ) {\n\tif ( isArrayArray( x ) ) {\n\t\tx = ndarray( x );\n\t} else if ( !isMatrixLike( x ) ) {\n\t\tconst msg = 'invalid input argument. The first argument must be a matrix or an array-of-arrays. Value: `' + x + '`';\n\t\tthrow new TypeError( msg );\n\t}\n\tif ( !isArrayLike( y ) ) {\n\t\tthrow new TypeError( 'invalid input argument. The second argument must be array-like. Value: `' + y + '`' );\n\t}\n\tconst fit = new GaussianFit( x, y );\n\treturn fit;\n}\n\n\n// EXPORTS //\n\nexport { multinomNB as multinomial, gaussianNB as gaussian };\n","// MODULES //\n\nimport isArrayLike from '@stdlib/assert/is-array-like';\nimport { isPrimitive as isNumber } from '@stdlib/assert/is-number';\n\n\n// MAIN //\n\n/**\n* Computes an element-wise subtraction.\n*\n* @param {NumberArray} arr - input array\n* @param {(NumberArray|number)} x - either an array of equal length or a scalar\n* @returns {NumberArray} output array\n*/\nfunction subtract( arr, x ) {\n\tconst isArr = isArrayLike( x );\n\tif ( !isArrayLike( arr ) ) {\n\t\tthrow new TypeError( 'invalid input argument. Must provide an array. Value: `' + arr + '`.' );\n\t}\n\tif ( !isArr && !isNumber( x ) ) {\n\t\tthrow new TypeError( 'invalid input argument. Second argument must either be an array or number primitive. Value: `' + x + '`.' );\n\t}\n\tconst len = arr.length;\n\tconst out = new Array( len );\n\n\t// Case 1: x is an array\n\tif ( isArr ) {\n\t\tif ( len !== x.length ) {\n\t\t\tthrow new Error( 'invalid input argument. Array to be added must have a length equal to that of the input array.' );\n\t\t}\n\t\tfor ( let i = 0; i < len; i++ ) {\n\t\t\tout[ i ] = arr[ i ] - x[ i ];\n\t\t}\n\t}\n\t// Case 2: scalar\n\telse {\n\t\tfor ( let i = 0; i < len; i++ ) {\n\t\t\tout[ i ] = arr[ i ] - x;\n\t\t}\n\t}\n\treturn out;\n}\n\n\n// EXPORTS //\n\nexport default subtract;\n"],"sourceRoot":""}